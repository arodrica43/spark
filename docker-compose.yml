version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: spark-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-sparkuser}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-sparkpass}
      POSTGRES_DB: ${POSTGRES_DB:-sparkdb}
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/scripts/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-sparkuser}"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: spark-redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: spark-backend
    environment:
      FLASK_APP: app.main:create_app
      FLASK_ENV: ${FLASK_ENV:-development}
      DATABASE_URL: postgresql://${POSTGRES_USER:-sparkuser}:${POSTGRES_PASSWORD:-sparkpass}@postgres:5432/${POSTGRES_DB:-sparkdb}
      REDIS_URL: redis://redis:6379/0
      SECRET_KEY: ${SECRET_KEY:-dev-secret-key-change-in-production}
    ports:
      - "${BACKEND_PORT:-5000}:5000"
    volumes:
      - ./backend:/app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: flask run --host=0.0.0.0

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: development
    container_name: spark-frontend
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      API_URL: ${API_URL:-http://localhost:5000}
    ports:
      - "${FRONTEND_PORT:-4200}:4200"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on:
      - backend
    command: npm start

  spark-master:
    build:
      context: ./spark-jobs
      dockerfile: Dockerfile
    container_name: spark-master
    environment:
      SPARK_MODE: master
      SPARK_MASTER_HOST: spark-master
      SPARK_MASTER_PORT: 7077
      SPARK_MASTER_WEBUI_PORT: 8080
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./spark-jobs:/opt/spark-jobs
      - spark_data:/tmp/spark-events

  spark-worker:
    build:
      context: ./spark-jobs
      dockerfile: Dockerfile
    container_name: spark-worker
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 2g
    depends_on:
      - spark-master
    volumes:
      - ./spark-jobs:/opt/spark-jobs
      - spark_data:/tmp/spark-events

volumes:
  postgres_data:
  redis_data:
  spark_data:
